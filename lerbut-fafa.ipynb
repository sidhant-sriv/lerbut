{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ee78d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"mistral\",  callbacks=CallbackManager([StreamingStdOutCallbackHandler()]),num_gpu=1, base_url=\"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello! Here's a simple \"Hello World\" program in Python:\n",
      "\n",
      "```python\n",
      "print(\"Hello World\")\n",
      "```\n",
      "\n",
      "When you run this code, it will print the message \"Hello World\" to the console. Is there a specific programming language or topic you have in mind that you'd like some help with? Let me know and I'll do my best to assist you!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Hello! Here\\'s a simple \"Hello World\" program in Python:\\n\\n```python\\nprint(\"Hello World\")\\n```\\n\\nWhen you run this code, it will print the message \"Hello World\" to the console. Is there a specific programming language or topic you have in mind that you\\'d like some help with? Let me know and I\\'ll do my best to assist you!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sid/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "modelPath = \"BAAI/bge-small-en\"\n",
    "\n",
    "# Create a dictionary with model configuration options, specifying to use the CPU for computations\n",
    "model_kwargs = {'device':'cuda:0'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath,     # Provide the pre-trained model's path\n",
    "    model_kwargs=model_kwargs, # Pass the model configuration options\n",
    "    encode_kwargs=encode_kwargs # Pass the encoding options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = DirectoryLoader('mytext', glob='*.txt', loader_cls=TextLoader)\n",
    "documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5098bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"data.pdf\")\n",
    "documents = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1296"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "# print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = './db'\n",
    "vectordb = Chroma.from_documents(documents=texts, \n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "dev = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={'k':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To do grade improvement, you need to follow the rules set by your institution's Grade Improvement policy. Generally, this involves retaking courses where you earned low grades during the regular Fall or Winter semesters. However, it's important to note that not all institutions offer grade improvement in summer or weekend semesters. Therefore, make sure to check with your Head of Department (HoD) Dr. Priya G for specific instructions regarding grade improvement and the number of credits to be considered under each category (Programme Elective / Discipline Elective and University Elective / Open Elective). If the grade after grade improvement is lesser than the actual grade, then the actual grade will be considered instead. For further queries, you can contact the Student Record section at ara@vit.ac.in. To do grade improvement, you need to follow the rules set by your institution's Grade Improvement policy. Generally, this involves retaking courses where you earned low grades during the regular Fall or Winter semesters. However, it's important to note that not all institutions offer grade improvement in summer or weekend semesters. Therefore, make sure to check with your Head of Department (HoD) Dr. Priya G for specific instructions regarding grade improvement and the number of credits to be considered under each category (Programme Elective / Discipline Elective and University Elective / Open Elective). If the grade after grade improvement is lesser than the actual grade, then the actual grade will be considered instead. For further queries, you can contact the Student Record section at ara@vit.ac.in.\n",
      "\n",
      "\n",
      "Sources:\n",
      "data.pdf\n",
      "data.pdf\n",
      "data.pdf\n",
      "data.pdf\n",
      "data.pdf\n"
     ]
    }
   ],
   "source": [
    "query = \"How to do grade improvement? \"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
